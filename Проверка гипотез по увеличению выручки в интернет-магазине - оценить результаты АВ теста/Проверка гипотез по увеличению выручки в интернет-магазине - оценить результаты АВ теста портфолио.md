<h1>Оглавление<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#Введение" data-toc-modified-id="Введение-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Введение</a></span></li><li><span><a href="#Загрузка-и-первичный-анализ-данных" data-toc-modified-id="Загрузка-и-первичный-анализ-данных-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Загрузка и первичный анализ данных</a></span></li><li><span><a href="#Предобработка-данных" data-toc-modified-id="Предобработка-данных-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Предобработка данных</a></span><ul class="toc-item"><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-3.1"><span class="toc-item-num">3.1&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Приоритезация-гипотез" data-toc-modified-id="Приоритезация-гипотез-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>Приоритезация гипотез</a></span><ul class="toc-item"><li><span><a href="#Приоритезация-гипотез" data-toc-modified-id="Приоритезация-гипотез-4.1"><span class="toc-item-num">4.1&nbsp;&nbsp;</span>Приоритезация гипотез</a></span><ul class="toc-item"><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-4.1.1"><span class="toc-item-num">4.1.1&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li></ul></li><li><span><a href="#Анализ-A/B-теста" data-toc-modified-id="Анализ-A/B-теста-5"><span class="toc-item-num">5&nbsp;&nbsp;</span>Анализ A/B-теста</a></span><ul class="toc-item"><li><span><a href="#Постройте-график-кумулятивной-выручки-по-группам.-Сделайте-выводы-и-предположения." data-toc-modified-id="Постройте-график-кумулятивной-выручки-по-группам.-Сделайте-выводы-и-предположения.-5.1"><span class="toc-item-num">5.1&nbsp;&nbsp;</span>Постройте график кумулятивной выручки по группам. Сделайте выводы и предположения.</a></span><ul class="toc-item"><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-5.1.1"><span class="toc-item-num">5.1.1&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Кумулятивный-средний-чек" data-toc-modified-id="Кумулятивный-средний-чек-5.2"><span class="toc-item-num">5.2&nbsp;&nbsp;</span>Кумулятивный средний чек</a></span><ul class="toc-item"><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-5.2.1"><span class="toc-item-num">5.2.1&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Относительное-изменение-кумулятивного-чека" data-toc-modified-id="Относительное-изменение-кумулятивного-чека-5.3"><span class="toc-item-num">5.3&nbsp;&nbsp;</span>Относительное изменение кумулятивного чека</a></span><ul class="toc-item"><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-5.3.1"><span class="toc-item-num">5.3.1&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Постройте-график-кумулятивного-среднего-количества-заказов-на-посетителя-по-группам.-Сделайте-выводы-и-предположения." data-toc-modified-id="Постройте-график-кумулятивного-среднего-количества-заказов-на-посетителя-по-группам.-Сделайте-выводы-и-предположения.-5.4"><span class="toc-item-num">5.4&nbsp;&nbsp;</span>Постройте график кумулятивного среднего количества заказов на посетителя по группам. Сделайте выводы и предположения.</a></span><ul class="toc-item"><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-5.4.1"><span class="toc-item-num">5.4.1&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Постройте-график-относительного-изменения-кумулятивного-среднего-количества-заказов-на-посетителя-группы-B-к-группе-A.-Сделайте-выводы-и-предположения." data-toc-modified-id="Постройте-график-относительного-изменения-кумулятивного-среднего-количества-заказов-на-посетителя-группы-B-к-группе-A.-Сделайте-выводы-и-предположения.-5.5"><span class="toc-item-num">5.5&nbsp;&nbsp;</span>Постройте график относительного изменения кумулятивного среднего количества заказов на посетителя группы B к группе A. Сделайте выводы и предположения.</a></span><ul class="toc-item"><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-5.5.1"><span class="toc-item-num">5.5.1&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Постройте-точечный-график-количества-заказов-по-пользователям.-Сделайте-выводы-и-предположения." data-toc-modified-id="Постройте-точечный-график-количества-заказов-по-пользователям.-Сделайте-выводы-и-предположения.-5.6"><span class="toc-item-num">5.6&nbsp;&nbsp;</span>Постройте точечный график количества заказов по пользователям. Сделайте выводы и предположения.</a></span><ul class="toc-item"><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-5.6.1"><span class="toc-item-num">5.6.1&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Посчитайте-95-й-и-99-й-перцентили-количества-заказов-на-пользователя.-Выберите-границу-для-определения-аномальных-пользователей." data-toc-modified-id="Посчитайте-95-й-и-99-й-перцентили-количества-заказов-на-пользователя.-Выберите-границу-для-определения-аномальных-пользователей.-5.7"><span class="toc-item-num">5.7&nbsp;&nbsp;</span>Посчитайте 95-й и 99-й перцентили количества заказов на пользователя. Выберите границу для определения аномальных пользователей.</a></span><ul class="toc-item"><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-5.7.1"><span class="toc-item-num">5.7.1&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Постройте-точечный-график-стоимостей-заказов.-Сделайте-выводы-и-предположения." data-toc-modified-id="Постройте-точечный-график-стоимостей-заказов.-Сделайте-выводы-и-предположения.-5.8"><span class="toc-item-num">5.8&nbsp;&nbsp;</span>Постройте точечный график стоимостей заказов. Сделайте выводы и предположения.</a></span><ul class="toc-item"><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-5.8.1"><span class="toc-item-num">5.8.1&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Посчитайте-95-й-и-99-й-перцентили-стоимости-заказов.-Выберите-границу-для-определения-аномальных-заказов." data-toc-modified-id="Посчитайте-95-й-и-99-й-перцентили-стоимости-заказов.-Выберите-границу-для-определения-аномальных-заказов.-5.9"><span class="toc-item-num">5.9&nbsp;&nbsp;</span>Посчитайте 95-й и 99-й перцентили стоимости заказов. Выберите границу для определения аномальных заказов.</a></span><ul class="toc-item"><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-5.9.1"><span class="toc-item-num">5.9.1&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Посчитайте-статистическую-значимость-различий-в-среднем-количестве-заказов-на-посетителя-между-группами-по-«сырым»-данным.-Сделайте-выводы-и-предположения." data-toc-modified-id="Посчитайте-статистическую-значимость-различий-в-среднем-количестве-заказов-на-посетителя-между-группами-по-«сырым»-данным.-Сделайте-выводы-и-предположения.-5.10"><span class="toc-item-num">5.10&nbsp;&nbsp;</span>Посчитайте статистическую значимость различий в среднем количестве заказов на посетителя между группами по «сырым» данным. Сделайте выводы и предположения.</a></span><ul class="toc-item"><li><span><a href="#Подготовка-данных" data-toc-modified-id="Подготовка-данных-5.10.1"><span class="toc-item-num">5.10.1&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href="#Статистическая-значимость-различий-в-среднем-количестве-заказов-на-посетителя-между-группами-по-«сырым»-данным." data-toc-modified-id="Статистическая-значимость-различий-в-среднем-количестве-заказов-на-посетителя-между-группами-по-«сырым»-данным.-5.10.2"><span class="toc-item-num">5.10.2&nbsp;&nbsp;</span>Статистическая значимость различий в среднем количестве заказов на посетителя между группами по «сырым» данным.</a></span></li><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-5.10.3"><span class="toc-item-num">5.10.3&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Посчитайте-статистическую-значимость-различий-в-среднем-чеке-заказа-между-группами-по-«сырым»-данным.-Сделайте-выводы-и-предположения." data-toc-modified-id="Посчитайте-статистическую-значимость-различий-в-среднем-чеке-заказа-между-группами-по-«сырым»-данным.-Сделайте-выводы-и-предположения.-5.11"><span class="toc-item-num">5.11&nbsp;&nbsp;</span>Посчитайте статистическую значимость различий в среднем чеке заказа между группами по «сырым» данным. Сделайте выводы и предположения.</a></span><ul class="toc-item"><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-5.11.1"><span class="toc-item-num">5.11.1&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Посчитайте-статистическую-значимость-различий-в-среднем-количестве-заказов-на-посетителя-между-группами-по-«очищенным»-данным.-Сделайте-выводы-и-предположения." data-toc-modified-id="Посчитайте-статистическую-значимость-различий-в-среднем-количестве-заказов-на-посетителя-между-группами-по-«очищенным»-данным.-Сделайте-выводы-и-предположения.-5.12"><span class="toc-item-num">5.12&nbsp;&nbsp;</span>Посчитайте статистическую значимость различий в среднем количестве заказов на посетителя между группами по «очищенным» данным. Сделайте выводы и предположения.</a></span><ul class="toc-item"><li><span><a href="#подготовка-данных." data-toc-modified-id="подготовка-данных.-5.12.1"><span class="toc-item-num">5.12.1&nbsp;&nbsp;</span>подготовка данных.</a></span></li><li><span><a href="#Cтатистическая-значимость-различий-в-среднем-количестве-заказов-на-посетителя-между-группами-по-«очищенным»-данным." data-toc-modified-id="Cтатистическая-значимость-различий-в-среднем-количестве-заказов-на-посетителя-между-группами-по-«очищенным»-данным.-5.12.2"><span class="toc-item-num">5.12.2&nbsp;&nbsp;</span>Cтатистическая значимость различий в среднем количестве заказов на посетителя между группами по «очищенным» данным.</a></span></li><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-5.12.3"><span class="toc-item-num">5.12.3&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Посчитайте-статистическую-значимость-различий-в-среднем-чеке-заказа-между-группами-по-«очищенным»-данным.-Сделайте-выводы-и-предположения." data-toc-modified-id="Посчитайте-статистическую-значимость-различий-в-среднем-чеке-заказа-между-группами-по-«очищенным»-данным.-Сделайте-выводы-и-предположения.-5.13"><span class="toc-item-num">5.13&nbsp;&nbsp;</span>Посчитайте статистическую значимость различий в среднем чеке заказа между группами по «очищенным» данным. Сделайте выводы и предположения.</a></span><ul class="toc-item"><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-5.13.1"><span class="toc-item-num">5.13.1&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Выводы" data-toc-modified-id="Выводы-5.14"><span class="toc-item-num">5.14&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li></ul></div>

# Декомпозиция

- **Введение**
- **Загрузка и первичный анализ данных**
    - Загрузка необходимых библиотек
    - Загрузка датасетов о визитах, заказах и рекламных расходов
    - Первичное изучение данных
    - Промежуточный вывод
    - Выполнить предобработку 
- **Предобработка** 
- **Приоритизация гипотез.** В файле "hypothesis" 9 гипотез по увеличению выручки интернет-магазина с указанными параметрами Reach, Impact, Confidence, Effort.
    - Использовать фреймворк ICE для приоритизации гипотез. Отсортировать их по убыванию приоритета.
    - Использовать фреймворк RICE для приоритизации гипотез. Отсортировать их по убыванию приоритета.
    - Указать, как изменилась приоритизация гипотез при применении RICE вместо ICE. Объяснить, почему так произошло.
- **Анализ A/B-теста.** Результаты A/B-теста описаны в файлах "orders" и "visitors".
    - Построить график кумулятивной выручки по группам. Сделать выводы и предположения.
    - Построить график кумулятивного среднего чека по группам. Сделать выводы и предположения.
    - Построить график относительного изменения кумулятивного среднего чека группы B к группе A. Сделать выводы и предположения.
    - Построить график кумулятивного среднего количества заказов на посетителя по группам. Сделать выводы и предположения.
    - Построить график относительного изменения кумулятивного среднего количества заказов на посетителя группы B к группе A. Сделать выводы и предположения.
    - Построить точечный график количества заказов по пользователям. Сделать выводы и предположения.
    - Посчитать 95-й и 99-й перцентили количества заказов на пользователя. Выбрать границу для определения аномальных пользователей.
    - Построить точечный график стоимостей заказов. Сделать выводы и предположения.
    - Посчитать 95-й и 99-й перцентили стоимости заказов. Выбрать границу для определения аномальных заказов.
    - Посчитать статистическую значимость различий в среднем количестве заказов на посетителя между группами по «сырым» данным. Сделать выводы и предположения.
    - Посчитать статистическую значимость различий в среднем чеке заказа между группами по «сырым» данным. Сделать выводы и предположения.
    - Посчитать статистическую значимость различий в среднем количестве заказов на посетителя между группами по «очищенным» данным. Сделать выводы и предположения.
    - Посчитать статистическую значимость различий в среднем чеке заказа между группами по «очищенным» данным. Сделать выводы и предположения.
- **Выводы**
    - Принять решение по результатам теста и объяснить его. Варианты решений:
        1. Остановить тест, зафиксировать победу одной из групп.
        2. Остановить тест, зафиксировать отсутствие различий между группами.
        3. Продолжить тест.

# Проверка гипотез по увеличению выручки в интернет-магазине - оценка результатов A/B-теста

## Введение

Работа будет проводится с крупным интернет-магазином. Необходимо увеличить выручку магазина приоритезировав гипотезы, которые были предварительно подготовлены, и провести A/B тестирования, после чего проанализировать результаты и дать рекомендации интернет-магазину.

## Загрузка и первичный анализ данных


```python
import pandas as pd
import datetime as dt
import numpy as np
import scipy.stats as stats
import matplotlib.pyplot as plt
```


```python
data = pd.read_csv(r'C:\Users\egor1\OneDrive\Рабочий стол\All\ПРАКТИКУМ\Проекты Практикум\БАЗЫ ДАННЫХ\Интернет магазин -оценка A-В теста/hypothesis.csv')
orders = pd.read_csv(r'C:\Users\egor1\OneDrive\Рабочий стол\All\ПРАКТИКУМ\Проекты Практикум\БАЗЫ ДАННЫХ\Интернет магазин -оценка A-В теста/orders.csv', sep=',')
visitors = pd.read_csv(r'C:\Users\egor1\OneDrive\Рабочий стол\All\ПРАКТИКУМ\Проекты Практикум\БАЗЫ ДАННЫХ\Интернет магазин -оценка A-В теста/visitors.csv', sep=',')
```

## Предобработка данных


```python
print(f'Количество дуюликатов в таблице orders: {orders.duplicated().sum()}')
```

    Количество дуюликатов в таблице orders: 0
    


```python
print(f'Количество дуюликатов в таблице visitors: {visitors.duplicated().sum()}')
```

    Количество дуюликатов в таблице visitors: 0
    


```python
orders.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>transactionId</th>
      <th>visitorId</th>
      <th>revenue</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1.197000e+03</td>
      <td>1.197000e+03</td>
      <td>1.197000e+03</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.155621e+09</td>
      <td>2.165960e+09</td>
      <td>8.348006e+03</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.229085e+09</td>
      <td>1.236014e+09</td>
      <td>3.919113e+04</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.062393e+06</td>
      <td>5.114589e+06</td>
      <td>5.000000e+01</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.166776e+09</td>
      <td>1.111826e+09</td>
      <td>1.220000e+03</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2.145194e+09</td>
      <td>2.217985e+09</td>
      <td>2.978000e+03</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>3.237740e+09</td>
      <td>3.177606e+09</td>
      <td>8.290000e+03</td>
    </tr>
    <tr>
      <th>max</th>
      <td>4.293856e+09</td>
      <td>4.283872e+09</td>
      <td>1.294500e+06</td>
    </tr>
  </tbody>
</table>
</div>




```python
visitors.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>visitors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>62.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>607.290323</td>
    </tr>
    <tr>
      <th>std</th>
      <td>114.400560</td>
    </tr>
    <tr>
      <th>min</th>
      <td>361.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>534.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>624.500000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>710.500000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>770.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
orders.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 1197 entries, 0 to 1196
    Data columns (total 5 columns):
     #   Column         Non-Null Count  Dtype 
    ---  ------         --------------  ----- 
     0   transactionId  1197 non-null   int64 
     1   visitorId      1197 non-null   int64 
     2   date           1197 non-null   object
     3   revenue        1197 non-null   int64 
     4   group          1197 non-null   object
    dtypes: int64(3), object(2)
    memory usage: 46.9+ KB
    


```python
visitors.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 62 entries, 0 to 61
    Data columns (total 3 columns):
     #   Column    Non-Null Count  Dtype 
    ---  ------    --------------  ----- 
     0   date      62 non-null     object
     1   group     62 non-null     object
     2   visitors  62 non-null     int64 
    dtypes: int64(1), object(2)
    memory usage: 1.6+ KB
    

### Промежуточные выводы

Данные просмотрели, изучили, каких-то грубых ошибок в данных не нашли, поэтому продолжаем с ними работать

## Приоритезация гипотез

### Приоритезация гипотез


```python
ice_score = round((data['Confidence']*data['Impact'])/data['Efforts'], 3)
```


```python
ice_score
```




    0    13.333
    1     2.000
    2     7.000
    3     1.125
    4     1.000
    5     1.333
    6     8.000
    7    11.200
    8    16.200
    dtype: float64




```python
rice_score = round((data['Confidence']*data['Impact']*data['Reach'])/data['Efforts'], 3)
```


```python
rice_score
```




    0     40.0
    1      4.0
    2     56.0
    3      9.0
    4      3.0
    5      4.0
    6     40.0
    7    112.0
    8     16.2
    dtype: float64




```python
data['Ice'] = ice_score
```


```python
data['Rice'] = rice_score
```


```python
pd.options.display.max_colwidth = 100
```


```python
data.sort_values(by='Rice', ascending=False)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Hypothesis</th>
      <th>Reach</th>
      <th>Impact</th>
      <th>Confidence</th>
      <th>Efforts</th>
      <th>Ice</th>
      <th>Rice</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7</th>
      <td>Добавить форму подписки на все основные страницы, чтобы собрать базу клиентов для email-рассылок</td>
      <td>10</td>
      <td>7</td>
      <td>8</td>
      <td>5</td>
      <td>11.200</td>
      <td>112.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Добавить блоки рекомендаций товаров на сайт интернет магазина, чтобы повысить конверсию и средни...</td>
      <td>8</td>
      <td>3</td>
      <td>7</td>
      <td>3</td>
      <td>7.000</td>
      <td>56.0</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Добавить два новых канала привлечения трафика, что позволит привлекать на 30% больше пользователей</td>
      <td>3</td>
      <td>10</td>
      <td>8</td>
      <td>6</td>
      <td>13.333</td>
      <td>40.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Показать на главной странице баннеры с актуальными акциями и распродажами, чтобы увеличить конве...</td>
      <td>5</td>
      <td>3</td>
      <td>8</td>
      <td>3</td>
      <td>8.000</td>
      <td>40.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Запустить акцию, дающую скидку на товар в день рождения</td>
      <td>1</td>
      <td>9</td>
      <td>9</td>
      <td>5</td>
      <td>16.200</td>
      <td>16.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Изменить структура категорий, что увеличит конверсию, т.к. пользователи быстрее найдут нужный товар</td>
      <td>8</td>
      <td>3</td>
      <td>3</td>
      <td>8</td>
      <td>1.125</td>
      <td>9.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Запустить собственную службу доставки, что сократит срок доставки заказов</td>
      <td>2</td>
      <td>5</td>
      <td>4</td>
      <td>10</td>
      <td>2.000</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Добавить страницу отзывов клиентов о магазине, что позволит увеличить количество заказов</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>1.333</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Изменить цвет фона главной страницы, чтобы увеличить вовлеченность пользователей</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1.000</td>
      <td>3.0</td>
    </tr>
  </tbody>
</table>
</div>



#### Промежуточные выводы

В своей приоритезации я решил в основном опираться на коэффииент Rice, так как он работает точнее из-за наличия в нем коэффициента Reach (охвата). И в гипотезе "Добавить форму подписки на все основные страницы, чтобы собрать базу клиентов для email-рассылок" он достигает максимальной оценки, из-за этого это самая приоритетная гипотеза, тогда как по коэффицинета Ice самая приоритетная гипотеза "Запустить акцию, дающую скидку на товар в день рождения	". Но в нашем списке эта гипотеза находится в середине списка. Рекомендую к тестировани. гипотезу "Добавить форму подписки на все основные страницы, чтобы собрать базу клиентов для email-рассылок" и если возможно, то "Добавить блоки рекомендаций товаров на сайт интернет магазина, чтобы повысить конверсию и средни...	". 

## Анализ A/B-теста

### Постройте график кумулятивной выручки по группам. Сделайте выводы и предположения.


```python
orders.head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>transactionId</th>
      <th>visitorId</th>
      <th>date</th>
      <th>revenue</th>
      <th>group</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3667963787</td>
      <td>3312258926</td>
      <td>2019-08-15</td>
      <td>1650</td>
      <td>B</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2804400009</td>
      <td>3642806036</td>
      <td>2019-08-15</td>
      <td>730</td>
      <td>B</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2961555356</td>
      <td>4069496402</td>
      <td>2019-08-15</td>
      <td>400</td>
      <td>A</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3797467345</td>
      <td>1196621759</td>
      <td>2019-08-15</td>
      <td>9759</td>
      <td>B</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2282983706</td>
      <td>2322279887</td>
      <td>2019-08-15</td>
      <td>2308</td>
      <td>B</td>
    </tr>
  </tbody>
</table>
</div>




```python
ordersgroup = orders.groupby('visitorId')['group'].nunique()
clean_orders = orders.merge(ordersgroup, on='visitorId')
orders = clean_orders[clean_orders['group_y']==1][['transactionId', 'visitorId', 'date', 'revenue', 'group_x']]
orders.columns = ['transactionId', 'visitorId', 'date', 'revenue', 'group']
```


```python
orders.head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>transactionId</th>
      <th>visitorId</th>
      <th>date</th>
      <th>revenue</th>
      <th>group</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3667963787</td>
      <td>3312258926</td>
      <td>2019-08-15</td>
      <td>1650</td>
      <td>B</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2804400009</td>
      <td>3642806036</td>
      <td>2019-08-15</td>
      <td>730</td>
      <td>B</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3797467345</td>
      <td>1196621759</td>
      <td>2019-08-15</td>
      <td>9759</td>
      <td>B</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2282983706</td>
      <td>2322279887</td>
      <td>2019-08-15</td>
      <td>2308</td>
      <td>B</td>
    </tr>
    <tr>
      <th>6</th>
      <td>182168103</td>
      <td>935554773</td>
      <td>2019-08-15</td>
      <td>2210</td>
      <td>B</td>
    </tr>
  </tbody>
</table>
</div>




```python
orders["date"] = orders["date"].map(lambda x: dt.datetime.strptime(x, '%Y-%m-%d'))
```


```python
visitors['date'] = visitors['date'].map( lambda x: dt.datetime.strptime(x, '%Y-%m-%d'))
```


```python
datesGroups = orders[['date', 'group']].drop_duplicates()
```


```python
ordersAggregated = datesGroups.apply(lambda x: orders[np.logical_and(orders['date'] <= x['date'], orders['group'] == x['group'])]\
                                     .agg({'date' : 'max', 'group' : 'max', 'transactionId' : 'nunique', 'visitorId' : 'nunique',\
                                           'revenue' : 'sum'}), axis=1).sort_values(by=['date', 'group'])


```


```python
visitorsAggregated = datesGroups.apply(lambda x: visitors[np.logical_and(visitors['date'] <= x['date'], visitors['group'] == x\
                                                                         ['group'])].agg({'date' : 'max', 'group' : 'max',\
                                                                                          'visitors' : 'sum'}), axis=1)\
.sort_values(by=['date', 'group'])

```


```python
cumulativeDate = ordersAggregated.merge(visitorsAggregated, left_on=['date', 'group'], right_on=['date', 'group'])
```


```python
cumulativeDate.columns=['date', 'group', 'orders', 'buyers', 'revenue', 'visitors']
```


```python
cumulativeDateA = cumulativeDate[cumulativeDate['group']=='A'][['date', 'revenue', 'orders']]
```


```python
cumulativeDateB = cumulativeDate[cumulativeDate['group']=='B'][['date', 'revenue', 'orders']]
```


```python
povtor = orders.groupby('visitorId')['group'].nunique()
povtor_table = orders.merge(povtor, on='visitorId')
```


```python
povtor_table[povtor_table['group_y']==2]['visitorId'].count()
```




    0




```python
plt.figure(figsize=(15, 8))
plt.plot(cumulativeDateA['date'], cumulativeDateA['revenue'], label='Кумулятивная выручка группы: A')
plt.plot(cumulativeDateB['date'], cumulativeDateB['revenue'], label='Кумулятивная выручка группы: B')
plt.ylabel('Выручка')
plt.xlabel('Даты')
plt.title('График кумулятивной выручки группы А и В')
plt.grid()
plt.legend();
```


    
![png](output_46_0.png)
    



```python
cumulativeDateB.query('"2019-08-17" <= date <= "2019-08-21"')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>date</th>
      <th>revenue</th>
      <th>orders</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>33</th>
      <td>2019-08-17</td>
      <td>2155542</td>
      <td>320</td>
    </tr>
    <tr>
      <th>35</th>
      <td>2019-08-18</td>
      <td>2190865</td>
      <td>327</td>
    </tr>
    <tr>
      <th>37</th>
      <td>2019-08-19</td>
      <td>3620785</td>
      <td>348</td>
    </tr>
    <tr>
      <th>39</th>
      <td>2019-08-20</td>
      <td>3768059</td>
      <td>368</td>
    </tr>
    <tr>
      <th>41</th>
      <td>2019-08-21</td>
      <td>3908406</td>
      <td>380</td>
    </tr>
  </tbody>
</table>
</div>




```python
orders.query(' date == "2019-08-19" ').sort_values(by='revenue', ascending=False).head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>transactionId</th>
      <th>visitorId</th>
      <th>date</th>
      <th>revenue</th>
      <th>group</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>506</th>
      <td>590470918</td>
      <td>1920142716</td>
      <td>2019-08-19</td>
      <td>1294500</td>
      <td>B</td>
    </tr>
    <tr>
      <th>608</th>
      <td>3970235543</td>
      <td>2912540959</td>
      <td>2019-08-19</td>
      <td>43990</td>
      <td>A</td>
    </tr>
    <tr>
      <th>605</th>
      <td>1570513684</td>
      <td>2837914161</td>
      <td>2019-08-19</td>
      <td>33405</td>
      <td>B</td>
    </tr>
    <tr>
      <th>502</th>
      <td>3765974140</td>
      <td>1357170471</td>
      <td>2019-08-19</td>
      <td>31680</td>
      <td>A</td>
    </tr>
    <tr>
      <th>538</th>
      <td>2683113224</td>
      <td>154576532</td>
      <td>2019-08-19</td>
      <td>26550</td>
      <td>B</td>
    </tr>
  </tbody>
</table>
</div>



#### Промежуточные выводы

На графике видно, что группа В приносит  больше выручки в отличие группы А. Также есть какой-то резкий скачок между 17 и 21 числом. В первые 4 дня выручка у групп была практически одинаковая, но потом группа В стала приносить больше. 13 августа кумулятивная выручка у обеих групп была почти одинаковой, но уже в конце видна значительная разница кумулятивной выручки двух групп.

Проверив данные с 17 по 21 августа, было выявленно, что резкий скачок был связан с одним крупным заказом 19 августа, который просто сильно отличался по стоимости от других заказов (в большую сторону). Этот заказ отвалится при отчистке данных, так как является аномалией.

### Кумулятивный средний чек


```python
plt.figure(figsize=(15, 8))
plt.plot(cumulativeDateA['date'], cumulativeDateA['revenue']/cumulativeDateA['orders'], label='Кумулятивная выручка группы: A')
plt.plot(cumulativeDateB['date'], cumulativeDateB['revenue']/cumulativeDateB['orders'], label='Кумулятивная выручка группы: B')
plt.title('График кумулятивного среднего чека групп А и В')
plt.ylabel('Средний чек')
plt.xlabel('Даты')
plt.grid()
plt.legend();
```


    
![png](output_52_0.png)
    


#### Промежуточные выводы

На графике мы видем, что вначале средний чек группы В резко возрос, обогнав группы А, когда у нее было падение, затем было падение 5 августа, но после этого в средний чек снова возрос и только к 13 августу группа А снова перегнала группу Б но не на долго. Тот огронмный заказ отразился и на этом графике, из-за чего мы и видим резкий скачок 19 августа, и после него стабильное падение группы В, но при этом группа А почти всегда хуже по показателю кумулятивного среднего чека.

### Относительное изменение кумулятивного чека


```python
mergedCumulativeRevenue = cumulativeDateA.merge(cumulativeDateB, left_on=['date'], right_on=['date'], suffixes=['A', 'B'])
```


```python
plt.figure(figsize=(15, 8))
plt.plot(mergedCumulativeRevenue['date'], (mergedCumulativeRevenue['revenueB']/mergedCumulativeRevenue['ordersB']\
                                          )/(mergedCumulativeRevenue['revenueA']/mergedCumulativeRevenue['ordersA'])-1)
plt.ylabel('Относительное изменение')
plt.xlabel('Даты')
plt.title('Относительное изменение кумулятивного среднего чека')
plt.axhline(y = 0, color='red',  linestyle='--')
plt.grid();
```


    
![png](output_57_0.png)
    


#### Промежуточные выводы

Как мы видим на графике относительного изменения, группа В относительно группы А показываает лучшеи показатели. есть конечно падение, с 11 по 15 агуста, пик которрого 13 августа ,и в начале, но в остальное время группа В преобладает. С2 августа по 4 августа виден сильный рост, 5 августа падение, но не опускается ниже нуля. Затем с 5 8 такэе рост, а после уже падение. Хоть и в конце показатели групы В начинают снижаться. Тут также отображается наомальная покупка на большую сумму 19 августа.

### Постройте график кумулятивного среднего количества заказов на посетителя по группам. Сделайте выводы и предположения.


```python
cumulativeDate['conversion'] = cumulativeDate['orders']/cumulativeDate['visitors']
```


```python
cumulativeDateA = cumulativeDate[cumulativeDate['group']=='A']
cumulativeDateB = cumulativeDate[cumulativeDate['group']=='B']
```


```python
plt.figure(figsize=(15,8))
plt.plot(cumulativeDateA['date'], cumulativeDateA['conversion'], label='Кумулятивная коверсия группы: А')
plt.plot(cumulativeDateB['date'], cumulativeDateB['conversion'], label='Кумулятивная коверсия группы: B')
plt.ylabel('График конверсии группы А и В')
plt.xlabel('Даты')
plt.title('Конверсия')
plt.grid()
plt.legend();
```


    
![png](output_63_0.png)
    


#### Промежуточные выводы

Как мы видим график очень не стабильный, особенно в начале. до 5 августа конверсия группы А преобладает (за исключением 2 августа, резкий всплеск группы В до 0,0348), но после 6 августа, группа В становится лидером и так в плоть до конца августа. Группа В стабильно в конце месяца держится у отметки в 0,034, когда группа А с периодическими всплесками держится на уровне 0,030. Думаю без всяких сомнений на этом график видно, что конерсия группы В выше конверсии группы А 

### Постройте график относительного изменения кумулятивного среднего количества заказов на посетителя группы B к группе A. Сделайте выводы и предположения.


```python
mergedCumulativeRevenue = cumulativeDateA[['date', 'conversion']].merge(cumulativeDateB[['date', 'conversion']],\
                                                                        left_on='date', right_on='date', suffixes=['A', 'B'])
```


```python
plt.figure(figsize=(15, 8))
plt.plot(mergedCumulativeRevenue['date'], (mergedCumulativeRevenue['conversionB']/mergedCumulativeRevenue['conversionA'])-1)
plt.title('Относительное изменение кумулятивной конверсии')
plt.xlabel('Даты')
plt.ylabel('Коэффициент изменения')
plt.axhline(y = 0, color='red',  linestyle='--')
plt.grid();
```


    
![png](output_68_0.png)
    


#### Промежуточные выводы

Гпафик относительного изменения кумулятивной конверсии практически в точности повторяет мой предыдущий вывод. Здесь также видно, что с 1 по 6 августа группа В имела конверсию ниже группы А,за исключением всплеска 2 августа, который виден на обеих графиках. И дальнейших рост группы В вплоть до 10 августа, а затем уже более равномерное распредлеение конверсии в группе В с периодическими всплесками и упадками. Максимальное значение изменения 0,21, которого смогли достичь 15 августа. И затем уже небольшое снижение с периодеским ростом изменения кумулятивной конверсии. К концу месяца изменение кумулятивной коверсии держится окло 0,14.

### Постройте точечный график количества заказов по пользователям. Сделайте выводы и предположения.


```python
orderByUser = orders.drop(['revenue', 'date', 'group'], axis=1)
```


```python
orderByUser = orders.groupby('visitorId', as_index=False).agg({'transactionId' : 'nunique'})
orderByUser.columns=['userId', 'order']
```


```python
x_values = pd.Series(range(0, len(orderByUser)))
plt.figure(figsize=(10, 5))
plt.scatter(x_values, orderByUser['order'])
plt.title('график количества заказов по пользователям')
plt.xlabel('Пользователь')
plt.ylabel('Количество заказов')
plt.grid();
```


    
![png](output_74_0.png)
    


#### Промежуточные выводы

На графике отчетливо видно что подавляющее количество заказов это 1, максимум 2. Далее количество заказов достаточно редко. Есть такие аномальные значения как 11 или 9 заказов. Для полноты картины необходимо посчитать перцентили

### Посчитайте 95-й и 99-й перцентили количества заказов на пользователя. Выберите границу для определения аномальных пользователей.


```python
np.percentile(orderByUser['order'], [90, 95, 99])
```




    array([1., 1., 2.])




```python
np.percentile(orderByUser['order'], [95, 96, 97, 98, 99])
```




    array([1., 1., 2., 2., 2.])



#### Промежуточные выводы

То есть не более 10 процентов от общего числа пользователей совершали более 1 заказа. Не более 5 процентов от общего числа пользователей совершали более 2 заказов. И не более 1 проента от общего чилса пользователей оформляли более 4 заказов.

Изучив более детально, было выяснено, что не больше 3 процентов от общего числа пользователей делали более 2 заказов. Далее надо будет отфильтровать данные избавившись от аномалий. Мы примем, что больее 2 заказов это аномалия.

### Постройте точечный график стоимостей заказов. Сделайте выводы и предположения.


```python
x_valuesR = pd.Series(range(0, len(orders)))
```


```python
plt.figure(figsize=(17, 5))
plt.scatter(x_valuesR, orders['revenue'])
plt.grid()
plt.title('Точечный график стимостей заказов')
plt.ylabel('Стоимость заказа, млн.')
plt.xlabel('порядковый номер заказа');
```


    
![png](output_85_0.png)
    



```python
big_orders = orders[['revenue']]
big_orders.sort_values(by='revenue', ascending=False).head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>revenue</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>506</th>
      <td>1294500</td>
    </tr>
    <tr>
      <th>1196</th>
      <td>202740</td>
    </tr>
    <tr>
      <th>1150</th>
      <td>92550</td>
    </tr>
    <tr>
      <th>803</th>
      <td>86620</td>
    </tr>
    <tr>
      <th>802</th>
      <td>67990</td>
    </tr>
    <tr>
      <th>1116</th>
      <td>66350</td>
    </tr>
    <tr>
      <th>1114</th>
      <td>65710</td>
    </tr>
    <tr>
      <th>989</th>
      <td>60450</td>
    </tr>
    <tr>
      <th>981</th>
      <td>58550</td>
    </tr>
    <tr>
      <th>680</th>
      <td>53904</td>
    </tr>
  </tbody>
</table>
</div>




```python
normalorders = orders[orders['revenue'] < 190000]['revenue']
xn_values = pd.Series(range(0,len(normalorders)))
plt.figure(figsize=(17, 5))
plt.scatter(xn_values, normalorders)
plt.grid()
plt.title('Точечный график стимостей заказов')
plt.ylabel('Стоимость заказа')
plt.xlabel('порядковый номер заказа');
```


    
![png](output_87_0.png)
    


#### Промежуточные выводы

На первом графике точечных стоимостей заказов не очень хорошо видна общая картина, но то что более 1,2 миллиона это явно выброс, который мы видели явно, он повлиял на предыдущие графики, данные были ограничены менее 1,2 млн. и построена новая таблица.

Также был выведен список самых дорогих заказов. Ярче всего выделяются первые два. Ограничим заказы по цене в 190000

На втором графике точечных стоимостей видно, что большинство заказов не превышает стоимость в 20000, но чтобы узнать все точно нам необходимо рассчитать перцентили.

### Посчитайте 95-й и 99-й перцентили стоимости заказов. Выберите границу для определения аномальных заказов.


```python
np.percentile(orders['revenue'], [90, 95, 99])
```




    array([17990., 26785., 53904.])




```python
np.percentile(orders['revenue'], [95, 96, 97, 98, 99])
```




    array([26785., 30649., 34792., 42353., 53904.])



#### Промежуточные выводы

По тому что я увидел, что менее 1 процента от общего количества заказов, стоимость более 58233. Я думаю, что границей можно принять 50000.

### Посчитайте статистическую значимость различий в среднем количестве заказов на посетителя между группами по «сырым» данным. Сделайте выводы и предположения.

#### Подготовка данных


```python
visitorsDailyA = visitors[visitors['group']=='A'][['date', 'visitors']]
visitorsDailyB = visitors[visitors['group']=='B'][['date', 'visitors']]
```


```python
visitorsDailyA.columns=['date', 'visitorsPerDateA']
visitorsDailyB.columns=['date', 'visitorsPerDateB']
```


```python
visitorsACummulative = visitorsDailyA.apply(lambda x: visitorsDailyA[visitorsDailyA['date'] <= x['date']]\
                                            .agg({'date' : 'max', 'visitorsPerDateA' : 'sum'}), axis=1)
visitorsBCummulative = visitorsDailyB.apply(lambda x: visitorsDailyB[visitorsDailyB['date'] <= x['date']]\
                                            .agg({'date' : 'max', 'visitorsPerDateB' : 'sum'}), axis=1)
```


```python
visitorsACummulative.columns=['date', 'visitorsCummulativeA']
visitorsBCummulative.columns=['date', 'visitorsCummulativeB']
```


```python
ordersDailyA = orders[orders['group']=='A'][['date', 'transactionId', 'visitorId', 'revenue']]\
.groupby('date', as_index=False).agg({'transactionId' : 'nunique', 'revenue' : 'sum'})
ordersDailyB = orders[orders['group']=='B'][['date', 'transactionId', 'visitorId', 'revenue']]\
.groupby('date', as_index=False).agg({'transactionId' : 'nunique', 'revenue' : 'sum'})
```


```python
ordersDailyA.columns=['date', 'ordersPerDateA', 'revenuePerDateA']
ordersDailyB.columns=['date', 'ordersPerDateB', 'revenuePerDateB']
```


```python
ordersACummulative = ordersDailyA.apply(lambda x: ordersDailyA[ordersDailyA['date'] <= x['date']]\
                                        .agg({'date':'max', 'ordersPerDateA':'sum', 'revenuePerDateA':'sum'}), axis=1).sort_values(by=['date'])
ordersBCummulative = ordersDailyB.apply(lambda x: ordersDailyB[ordersDailyB['date'] <= x['date']]\
                                        .agg({'date':'max', 'ordersPerDateB':'sum', 'revenuePerDateB':'sum'}), axis=1).sort_values(by=['date'])
```


```python
ordersACummulative.columns = ['date', 'ordersCummulativeA', 'revenueCummulativeA']
ordersBCummulative.columns = ['date', 'ordersCummulativeB', 'revenueCummulativeB']
```


```python
orders.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>transactionId</th>
      <th>visitorId</th>
      <th>date</th>
      <th>revenue</th>
      <th>group</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3667963787</td>
      <td>3312258926</td>
      <td>2019-08-15</td>
      <td>1650</td>
      <td>B</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2804400009</td>
      <td>3642806036</td>
      <td>2019-08-15</td>
      <td>730</td>
      <td>B</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3797467345</td>
      <td>1196621759</td>
      <td>2019-08-15</td>
      <td>9759</td>
      <td>B</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2282983706</td>
      <td>2322279887</td>
      <td>2019-08-15</td>
      <td>2308</td>
      <td>B</td>
    </tr>
    <tr>
      <th>6</th>
      <td>182168103</td>
      <td>935554773</td>
      <td>2019-08-15</td>
      <td>2210</td>
      <td>B</td>
    </tr>
  </tbody>
</table>
</div>




```python
data = visitorsDailyA.merge(visitorsDailyB, left_on='date', right_on='date', how='left')\
.merge(visitorsACummulative, left_on='date', right_on='date', how='left')\
.merge(visitorsBCummulative, left_on='date', right_on='date', how='left')\
.merge(ordersDailyA, left_on='date', right_on='date', how='left')\
.merge(ordersDailyB, left_on='date', right_on='date', how='left')\
.merge(ordersACummulative, left_on='date', right_on='date', how='left')\
.merge(ordersBCummulative, left_on='date', right_on='date', how='left')
```

#### Статистическая значимость различий в среднем количестве заказов на посетителя между группами по «сырым» данным.

За нулевую гипотезу возьмем, что: "Различий в среденем количестве заказов на посетителя между группами А и В по сырым данным нет." Альтернативная же, звучит так: "Различия в среденем количестве заказов на посетителя между группами А и В по сырым данным имеются."


```python
ordersByUserA = orders[orders['group']=='A'].groupby('visitorId', as_index=False).agg({'transactionId':'nunique'})
ordersByUserB = orders[orders['group']=='B'].groupby('visitorId', as_index=False).agg({'transactionId':'nunique'})
```


```python
ordersByUserA.columns=['userId', 'orders']
ordersByUserB.columns=['userId', 'orders']
```


```python
sampleA = pd.concat([ordersByUserA['orders'],\
                     pd.Series(0, index=np.arange(data['visitorsPerDateA'].sum() - len(ordersByUserA['orders'])),\
                               name='orders')], axis=0)
sampleB = pd.concat([ordersByUserB['orders'],\
                     pd.Series(0, index=np.arange(data['visitorsPerDateB'].sum() - len(ordersByUserB['orders'])),\
                               name='orders')], axis=0)

```


```python
print('alpha = 0,05')
print("p-value = {0:.3f}".format(stats.mannwhitneyu(sampleA, sampleB) [1]))
print("Относительный показатель 'B' и 'A' = {0:.3f}".format(sampleB.mean()/sampleA.mean() - 1))
```

    alpha = 0,05
    p-value = 0.011
    Относительный показатель 'B' и 'A' = 0.160
    

#### Промежуточные выводы

p-value = 0.017, что меньше alpha = 0,05. Это значит, что нулевую гипотезу о том что различий в среднем количестве заказов между группами А и В нет, мы отвергаем. Различия между группами имеются. И относительнй показатель показывает, что различия в 13,8 %

### Посчитайте статистическую значимость различий в среднем чеке заказа между группами по «сырым» данным. Сделайте выводы и предположения.

За нулевую гипотезу возьмем, что: "Различий в среденем чеке заказа между группами А и В по сырым данным нет." Альтернативная же, звучит так: "Различия в среденем чеке заказа между группами А и В по сырым данным имеются."


```python
print('alpha = 0,05')
print("p-value = {0:.3f}".format(stats.mannwhitneyu(orders[orders['group']=='A']['revenue'],\
                                                    orders[orders['group']=='B']['revenue'])[1]))
print("Относительный показатель 'B' и 'A' = {0:.3f}"\
      .format((orders[orders['group']=='B']['revenue']).mean()/(orders[orders['group']=='A']['revenue']).mean() - 1))
```

    alpha = 0,05
    p-value = 0.829
    Относительный показатель 'B' и 'A' = 0.287
    

#### Промежуточные выводы

p-value = 0.729, что больше alpha = 0.05. Из этого следует, что нулевую гипотезу о различии межджу группами А и В в среднем чеке заказа мы не можем отвергунть. При этом относительный прирост среднего чека группы В относительно группы А составляет 26%.

### Посчитайте статистическую значимость различий в среднем количестве заказов на посетителя между группами по «очищенным» данным. Сделайте выводы и предположения.

#### подготовка данных.


```python
usersWithManyOrders = pd.concat([ordersByUserA[ordersByUserA['orders'] > 2]['userId'],\
                                 ordersByUserB[ordersByUserB['orders'] > 2]['userId']], axis=0)
usersWithExpensiveOrders = orders[orders['revenue'] > 50000 ]['visitorId']
```


```python
abnormal = pd.concat([usersWithManyOrders, usersWithExpensiveOrders], axis=0).drop_duplicates().sort_values()
```


```python
print(f'Всего аномальных пользователей: {len(abnormal)}')
```

    Всего аномальных пользователей: 22
    


```python
sampleAFiltred = pd.concat([ordersByUserA[np.logical_not(ordersByUserA['userId'].isin(abnormal))]['orders'], \
                            pd.Series(0, index=np.arange(data['visitorsPerDateA'].sum() - len(ordersByUserA['orders'])), \
                                      name='orders')], axis=0)
sampleBFiltred = pd.concat([ordersByUserB[np.logical_not(ordersByUserB['userId'].isin(abnormal))]['orders'], \
                            pd.Series(0, index=np.arange(data['visitorsPerDateB'].sum() - len(ordersByUserB['orders'])), \
                                      name='orders')], axis=0)
```

####  Cтатистическая значимость различий в среднем количестве заказов на посетителя между группами по «очищенным» данным.

За нулевую гипотезу возьмем, что: "Различий в среденем количестве заказов на посетителя между группами А и В по очищенным данным нет." Альтернативная же, звучит так: "Различия в среденем количестве заказов на посетителя между группами А и В по очищенным данным имеются."


```python
print('alpha = 0,05')
print("p-value = {0:.3f}".format(stats.mannwhitneyu(sampleAFiltred, sampleBFiltred) [1]))
print("Относительный показатель 'B' и 'A' = {0:.3f}".format(sampleBFiltred.mean()/sampleAFiltred.mean() - 1))
```

    alpha = 0,05
    p-value = 0.006
    Относительный показатель 'B' и 'A' = 0.198
    

#### Промежуточные выводы

p-value = 0.008 меньше alpha = 0.05, следовательно нулевую гипотеза о отсутствии различий в среднем количестве заказов на посетителя между группами А и В, мы отвергаем. Относительный показатель показал, что разница между группами составляет около 18,2%.

### Посчитайте статистическую значимость различий в среднем чеке заказа между группами по «очищенным» данным. Сделайте выводы и предположения.

За нулевую гипотезу возьмем, что: "Различий в среденем чеке заказа между группами А и В по очищенным данным нет." Альтернативная же, звучит так: "Различия в среденем чеке заказа между группами А и В по очищенным данным имеются."


```python
print('alpha = 0,05')
print("p-value = {0:.3f}"\
      .format(stats.mannwhitneyu(orders[np.logical_and(orders['group']=='A',np.logical_not(orders['visitorId']\
                                                                                           .isin(abnormal)))]['revenue'],\
                                 orders[np.logical_and(orders['group']=='B',np.logical_not(orders['visitorId']\
                                                                                           .isin(abnormal)))] ['revenue'])[1]))
print("Относительный показатель 'B' и 'A' = {0:.3f}"\
.format((orders[np.logical_and(orders['group']=='B', np.logical_not(orders['visitorId'].isin(abnormal)))]['revenue'])\
.mean()/(orders[np.logical_and(orders['group']=='A', np.logical_not(orders['visitorId'].isin(abnormal)))]['revenue'])\
        .mean() - 1))
```

    alpha = 0,05
    p-value = 0.939
    Относительный показатель 'B' и 'A' = 0.011
    

#### Промежуточные выводы

p-value = 0.940, а alpha = 0.05, следовательно мы не можем отвергнуть нулевую гипотезу, о отсутсвии различий в среднем чеке заказа между группами А и В. При этом относительный прирост среднего чека группы В относительно группы А составляет 1,9%.

### Выводы

О чем нам сказали результаты тестов:
 - Мы отвергли по нулевую гипотезу об отсутсвие различий в среднем количестве заказов между группами по "Сырым данным", относительнй показатель различия составляет 13,8%;
 - Мы не смогли отвергнуть нулевую теорию об отсуствии различий в среднем чеке заказа между группами по "Сырым данным", относительный показатель различия составляет 26%;
 - Мы отвергли по нулевую гипотезу об отсутсвие различий в среднем количестве заказов между группами по "Очищенным данным", Относительный показатель составляет около 18,2%;
 - Мы не смогли отвергнуть нулевую теорию об отсуствии различий в среднем чеке заказа между группами по "Очищенным данным", относительный показатель различия групп составялет 1,9%;
 
Также на графиках мы наблюдали преобладание группы В по кумулятивном средним значениям количеством заказов на посетителей и по кумулятивному среднему чеку. Графики относительных показателей тоже показали, что группа В успешней чем группа А. В некоторых случаях в нчале месяца группа А преобладала, конечно, но под конец месяца группа В имела показатели значительно лучше чем группа А.

По итогу я могу сказать, что стоит остановить тест и признать группу В успшнее группы А, хоть и отличия по среднем чеку не большие.

В Работе так же была проведена приоритезация гипотез методами ICE и RICE, так как метод RICE более точный, я опирался на него. Также были убраны аномалии из данных, рассчитав перцентели.
